import numpy as np
import pandas as pd
import torch
from leaspy import AlgorithmSettings, Leaspy
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
import argparse
import os

from dataset.Dataset2D import Dataset2D
from longitudinalModel.fit_longitudinal_estimator_on_nn import fit_longitudinal_estimator_on_nn
from longitudinalModel.train import train, train_kfold
from dataset.group_based_train_test_split import group_based_train_test_split
from dataset.split_k_folds import train_k_folds_split

from nnModels.CVAE2D_ORIGINAL import CVAE2D_ORIGINAL
from nnModels.losses import spatial_auto_encoder_loss

from utils.display_individual_observations_2D import display_individual_observations_2D
from utils.loading_image import open_npy
from dataset.LongitudinalDataset2D import LongitudinalDataset2D, longitudinal_collate_2D
from nnModels.train_AE import train_AE, train_AE_kfold
from cross_validation import CV_VAE, CV_LVAE
"""
Script to train the full model. Neural network model + longitudinal estimator
"""
parser = argparse.ArgumentParser()
parser.add_argument('--data', type=str, required=False, default="./data_csv/starmen_dataset.csv",
                    help='csv file path')
parser.add_argument('--nnmodel_name', type=str, required=False, default='CVAE2D',
                    help='Name of the NN model that will be used')
parser.add_argument('--gamma', type=float, required=False, default=100,
                    help='hyperparameter gamma value used for computing the loss')
parser.add_argument('--beta', type=float, required=False, default=5,
                    help='hyperparameter beta value used for computing the loss, default = 5')
parser.add_argument('--dimension', type=int, required=False, default=4,
                    help='size of the latent representation generated by the neural network encoder, default =4')
parser.add_argument('--iterations', type=int, required=False, default=200,
                    help='Number of iterations when training the longitudinal estimator, default = 200')
parser.add_argument('--lr', type=float, required=False, default=1e-4,
                    help='Learning rate to train the VAE, default = 1e-4')
parser.add_argument('--batch_size', type=int, required=False, default=256,
                    help='batch_size to train the VAE, default = 256')
parser.add_argument("-skip", type=str, required=False, default="n")
args = parser.parse_args()

# First we get the different train/validation/test dataset
df = pd.read_csv(args.data)


train_val_df, test_df = group_based_train_test_split(df, test_size=0.2, group_col='subject_id', random_state=42)
test_df.to_csv('data_csv/starmen_test_set.csv', index=False)
folds_index = train_k_folds_split(train_val_df, 8)

###  Hyperparameters of the Variational autoencoder model
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print("device = ", device)
num_worker = round(os.cpu_count()/4)   # For faster GPU training

batch_size = args.batch_size
latent_representation_size = args.dimension
gamma = args.gamma
beta = args.beta
initial_lr = args.lr

# HERE TO CHANGE VAE ARCHITECTURE
model = CVAE2D_ORIGINAL(latent_representation_size)
model.gamma = gamma
model.beta = beta
loss_function = spatial_auto_encoder_loss
print(f"{args.nnmodel_name}_{latent_representation_size}_{beta}_{gamma}_{args.iterations}")

### Hyperparameters of the longitudinal estimator
all_losses = []
algo_settings = AlgorithmSettings('mcmc_saem', n_iter=args.iterations, seed=45, noise_model="gaussian_diagonal")

# Preparation of the data
transformations = transforms.Compose([])

# Path to save plots
output_path = f"plots/training_plots/VAE_folds/{args.nnmodel_name}_{latent_representation_size}_{beta}_{gamma}_{args.iterations}/"
os.makedirs(os.path.dirname(output_path), exist_ok=True)

# Training of the vanilla VAE
VAE_saving_path = f"saved_models_2D/VAE_folds/{args.nnmodel_name}_{latent_representation_size}_{beta}"
os.makedirs(os.path.dirname(f"saved_models_2D/VAE_folds/"), exist_ok=True)
path_best_fold_model = f"saved_models_2D/best_fold_{args.nnmodel_name}_{latent_representation_size}_{beta}.pth"

if args.skip == "n":
    train_AE_kfold(CVAE2D_ORIGINAL, folds_index, nb_epochs=300, device=device,
                nn_saving_path=VAE_saving_path,
                loss_graph_saving_path=output_path, spatial_loss=loss_function,
                batch_size=batch_size, num_workers=num_worker,
                latent_dimension=latent_representation_size, gamma=gamma, beta=beta)
    
    best_fold = CV_VAE(CVAE2D_ORIGINAL, folds_index, test_df, VAE_saving_path, plot_save_path=output_path,
                    latent_dimension=latent_representation_size, gamma=gamma, beta=beta,
                    batch_size=batch_size, num_worker=num_worker)

    model = CVAE2D_ORIGINAL(latent_representation_size)
    model.gamma = gamma
    model.beta = beta
    model.load_state_dict(torch.load(VAE_saving_path+f"_fold_{best_fold}.pth", map_location='cpu'))
    torch.save(model.state_dict(), path_best_fold_model)




# Training of the Longitudinal VAE
output_path = f"plots/training_plots/LVAE_folds/{args.nnmodel_name}_{latent_representation_size}_{beta}/"
LVAE_saving_path = f"saved_models_2D/LVAE_folds/{args.nnmodel_name}_{latent_representation_size}_{beta}_{gamma}_{args.iterations}"
longitudinal_saving_path = f'saved_models_2D/LVAE_folds/longitudinal_estimator_params_{args.nnmodel_name}_{latent_representation_size}_{beta}_{gamma}_{args.iterations}'
os.makedirs(os.path.dirname(output_path), exist_ok=True)

os.makedirs(os.path.dirname(LVAE_saving_path), exist_ok=True)
os.makedirs(os.path.dirname(longitudinal_saving_path), exist_ok=True)


best_loss = 1e15
best_loss, lvae_losses = train_kfold(CVAE2D_ORIGINAL, path_best_fold_model, folds_index, algo_settings, 
                                     nb_epochs=300, lr=initial_lr, latent_dimension=latent_representation_size,
                                     nn_saving_path=LVAE_saving_path, longitudinal_saving_path=longitudinal_saving_path,
                                     loss_graph_saving_path=f"{output_path}/loss_longitudinal_only", previous_best_loss=best_loss,
                                     spatial_loss=loss_function, batch_size=batch_size, num_workers=num_worker)

best_fold_LVAE = CV_LVAE(CVAE2D_ORIGINAL, folds_index, test_df, LVAE_saving_path, longitudinal_saving_path, latent_dimension=latent_representation_size, plot_save_path=output_path)


save_best_fold_path_VAE = f"saved_models_2D/best_fold_CVAE2D_{latent_representation_size}_{beta}_{gamma}_{args.iterations}.pth"
save_best_fold_path_LVAE = f"saved_models_2D/best_fold_longitudinal_estimator_params_CVAE2D_{latent_representation_size}_{beta}_{gamma}_{args.iterations}.json"

best_fold_model = CVAE2D_ORIGINAL(latent_representation_size)
best_fold_model.gamma = gamma
best_fold_model.beta = beta
best_fold_model.load_state_dict(torch.load(LVAE_saving_path+f"_fold_{best_fold_LVAE}.pth2", map_location='cpu'))
torch.save(best_fold_model.state_dict(), save_best_fold_path_VAE+"2")
longitudinal_estimator = Leaspy.load(longitudinal_saving_path+f"_fold_{best_fold_LVAE}.json2")
longitudinal_estimator.save(save_best_fold_path_LVAE+"2")

